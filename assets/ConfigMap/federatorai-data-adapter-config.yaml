apiVersion: v1
kind: ConfigMap
metadata:
  name: federatorai-data-adapter-config
  namespace: {{.NameSpace}}
data:
    telegraf.conf: |+
      [global_tags]

      [agent]
        interval = "1m"
        round_interval = true
        metric_batch_size = 1000
        metric_buffer_limit = 10000
        collection_jitter = "0s"
        flush_interval = "30s"
        flush_jitter = "0s"
        precision = "1us"
        debug = true
        logfile = "/var/log/telegraf.log"
        logfile_rotation_interval = "1d"
        logfile_rotation_max_archives = 7
        logfile_rotation_max_size = "100MB"
        ## Query will retry if some metrics hasn't returned yet.
        max_retry = 2
        retry_interval = "15s"
        quiet = false
        hostname = ""
        omit_hostname = false
        alamedascaler_enable = true

      [[aggregators.basicstats]]
        period = "1m"
        granularity = "1m"
        drop_original = true
        namedrop = ["federatorai.*", "federatorai_*","top_container_*","node_pod_phase_count"]

      [[aggregators.federatorai]]
        drop_original = true
        ##namepass = ["kafka_topic_partition_current_offset","kafka_consumer_group_current_offset","kafka_consumer_group_lag","federatorai.*.future"]
        namepass = ["federatorai_*"]

        ## Node ##
        [[aggregators.federatorai.metric]]
            measurement_name = "federatorai.prediction.node.avg"
            expression = "avg(avg_over_time(federatorai_prediction_node[1m]))by(kube_cluster,host,prediction_window,source_metric)"
            origin_information_from = "federatorai_prediction_node"
            fields = ["value"]

        [[aggregators.federatorai.metric]]
            measurement_name = "federatorai.prediction.node.min"
            expression = "min(min_over_time(federatorai_prediction_node[1m]))by(kube_cluster,host,prediction_window,source_metric)"
            origin_information_from = "federatorai_prediction_node"
            fields = ["value"]

        [[aggregators.federatorai.metric]]
            measurement_name = "federatorai.prediction.node.max"
            expression = "max(max_over_time(federatorai_prediction_node[1m]))by(kube_cluster,host,prediction_window,source_metric)"
            origin_information_from = "federatorai_prediction_node"
            fields = ["value"]

        ## Namespace ##
        [[aggregators.federatorai.metric]]
            measurement_name = "federatorai.prediction.namespace.avg"
            expression = "avg(avg_over_time(federatorai_prediction_namespace[1m]))by(kube_cluster,kube_namespace,prediction_window,source_metric)"
            origin_information_from = "federatorai_prediction_namespace"
            fields = ["value"]

        [[aggregators.federatorai.metric]]
            measurement_name = "federatorai.prediction.namespace.min"
            expression = "min(min_over_time(federatorai_prediction_namespace[1m]))by(kube_cluster,kube_namespace,prediction_window,source_metric)"
            origin_information_from = "federatorai_prediction_namespace"
            fields = ["value"]

        [[aggregators.federatorai.metric]]
            measurement_name = "federatorai.prediction.namespace.max"
            expression = "max(max_over_time(federatorai_prediction_namespace[1m]))by(kube_cluster,kube_namespace,prediction_window,source_metric)"
            origin_information_from = "federatorai_prediction_namespace"
            fields = ["value"]

        ## Controller ##
        [[aggregators.federatorai.metric]]
            measurement_name = "federatorai.prediction.controller.avg"
            expression = "avg(avg_over_time(federatorai_prediction_controller[1m]))by(kube_cluster,kube_namespace,prediction_window,source_metric,kube_deployment,kube_stateful_set,oshift_deployment_config)"
            origin_information_from = "federatorai_prediction_controller"
            fields = ["value"]

        [[aggregators.federatorai.metric]]
            measurement_name = "federatorai.prediction.controller.min"
            expression = "min(min_over_time(federatorai_prediction_controller[1m]))by(kube_cluster,kube_namespace,prediction_window,source_metric,kube_deployment,kube_stateful_set,oshift_deployment_config)"
            origin_information_from = "federatorai_prediction_controller"
            fields = ["value"]

        [[aggregators.federatorai.metric]]
            measurement_name = "federatorai.prediction.controller.max"
            expression = "max(max_over_time(federatorai_prediction_controller[1m]))by(kube_cluster,kube_namespace,prediction_window,source_metric,kube_deployment,kube_stateful_set,oshift_deployment_config)"
            origin_information_from = "federatorai_prediction_controller"
            fields = ["value"]

        ## Fedemeter ##
        [[aggregators.federatorai.metric]]
            measurement_name = "federatorai.prediction.namespace.cost"
            expression = "sum(sum_over_time(federatorai_prediction_namespace_cost[1m]))by(kube_cluster,kube_namespace,prediction_window,provider)"
            origin_information_from = "federatorai_prediction_namespace_cost"
            fields = ["value"]

        [[aggregators.federatorai.metric]]
            measurement_name = "federatorai.cost_analysis.namespace.cost"
            expression = "sum(sum_over_time(federatorai_cost_analysis_namespace_cost[1m]))by(kube_cluster,kube_namespace,prediction_window,provider)"
            origin_information_from = "federatorai_cost_analysis_namespace_cost"
            fields = ["value"]

        [[aggregators.federatorai.metric]]
            measurement_name = "federatorai.recommendation.instance"
            expression = "sum(sum_over_time(federatorai_recommendation_instance[1m]))by(kube_cluster,country,time_interval,instance_type,provider,region,pricing_option,display_name,ondemand_instance_master_num,reserved_instance_master_num,ondemand_instance_worker_num,reserved_instance_worker_num,spot_instance_master_num,spot_instance_worker_num)"
            origin_information_from = "federatorai_recommendation_instance"
            fields = ["value"]

        #[[aggregators.federatorai.metric]]
        #    measurement_name = "kafka_topic_partition_current_offset"
        #    expression = "sum(delta(kafka_topic_partition_current_offset[1m]))by(consumer_group,topic,namespace)"
        #    origin_information_from = "kafka_topic_partition_current_offset"
        #    fields = ["value"]
        #[[aggregators.federatorai.metric]]
        #    measurement_name = "kafka_consumer_group_current_offset"
        #    expression = "sum(delta(kafka_consumer_group_current_offset[1m]))by(consumer_group,topic,namespace)"
        #    origin_information_from = "kafka_consumer_group_current_offset"
        #    fields = ["value"]
        #[[aggregators.federatorai.metric]]
        #    measurement_name = "kafka_consumer_group_lag"
        #    expression = "sum(kafka_consumer_group_lag)by(namespace,consumer_group,topic)"
        #    origin_information_from = "kafka_consumer_group_lag"
        #    fields = ["value"]

      ## This plugin is for future 24 hours prediction
      [[inputs.alameda_datahub_query]]
        url = "$DATAHUB_URL"
        port = "$DATAHUB_PORT"
        query_start_time_offset = "0m"
        query_end_time_offset = "24h" #Support s(second),m(minute),h(hour)
        # If use_query_timestamp is true, agent will use queried timestamp from database as timestamp of the metric.
        # If use_query_timestamp is false, agent will use current timestamp as timestamp of the metric.
        use_query_timestamp = false
        cluster_name = "$CLUSTER_NAME"

        ### Prediction ###

        ## Node ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          measurement = "node"
          scope = "prediction"
          granularity = "3600"

        ## Namespace ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          measurement = "namespace"
          scope = "prediction"
          granularity = "3600"

        ## Controller ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          name = "<general_application_name>"
          namespace = "<general_application_namespace>"
          measurement = "controller"
          scope = "prediction"
          granularity = "3600"

      ## This plugin is for future 7 days prediction
      [[inputs.alameda_datahub_query]]
        url = "$DATAHUB_URL"
        port = "$DATAHUB_PORT"
        query_start_time_offset = "0m"
        query_end_time_offset = "168h" #Support s(second),m(minute),h(hour)
        # If use_query_timestamp is true, agent will use queried timestamp from database as timestamp of the metric.
        # If use_query_timestamp is false, agent will use current timestamp as timestamp of the metric.
        use_query_timestamp = false
        cluster_name = "$CLUSTER_NAME"

        ### Prediction ###

        ## Node ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          measurement = "node"
          scope = "prediction"
          granularity = "21600"

        ## Namespace ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          measurement = "namespace"
          scope = "prediction"
          granularity = "21600"

        ## Controller ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          name = "<general_application_name>"
          namespace = "<general_application_namespace>"
          measurement = "controller"
          scope = "prediction"
          granularity = "21600"

      ## This plugin is for future 30 days prediction
      [[inputs.alameda_datahub_query]]
        url = "$DATAHUB_URL"
        port = "$DATAHUB_PORT"
        query_start_time_offset = "0m"
        query_end_time_offset = "720h" #Support s(second),m(minute),h(hour)
        # If use_query_timestamp is true, agent will use queried timestamp from database as timestamp of the metric.
        # If use_query_timestamp is false, agent will use current timestamp as timestamp of the metric.
        use_query_timestamp = false
        cluster_name = "$CLUSTER_NAME"

        ### Prediction ###

        ## Node ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          measurement = "node"
          scope = "prediction"
          granularity = "86400"

        ## Namespace ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          measurement = "namespace"
          scope = "prediction"
          granularity = "86400"

        ## Controller ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          name = "<general_application_name>"
          namespace = "<general_application_namespace>"
          measurement = "controller"
          scope = "prediction"
          granularity = "86400"

        ### Fedemeter ###

        ## Cost Analysis - Recommended Provider Cost
        [[inputs.alameda_datahub_query.watched_source]] # Cost Analysis config
          measurement = "recommendation_jeri"
          scope = "fedemeter"
          granularity = "86400"

        ## Cost Allocation - Namespace Prediction Cost
        [[inputs.alameda_datahub_query.watched_source]] # Cost Analysis config
          measurement = "resource_prediction_cost_namespace"
          scope = "fedemeter"
          granularity = "86400"

      ## This plugin is for future 1 hour planning
      [[inputs.alameda_datahub_query]]
        url = "$DATAHUB_URL"
        port = "$DATAHUB_PORT"
        query_start_time_offset = "0m"
        query_end_time_offset = "1h"
        # If use_query_timestamp is true, agent will use queried timestamp from database as timestamp of the metric.
        # If use_query_timestamp is false, agent will use current timestamp as timestamp of the metric.
        use_query_timestamp = false
        cluster_name = "$CLUSTER_NAME"

        ### Planning ###

        ## Node ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          measurement = "node"
          scope = "planning"
          granularity = "3600"

        ## Namespace ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          measurement = "namespace"
          scope = "planning"
          granularity = "3600"

        ## Controller ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          name = "<general_application_name>"
          namespace = "<general_application_namespace>"
          measurement = "controller"
          scope = "planning"
          granularity = "3600"

      ## This plugin is for future 6 hours planning
      [[inputs.alameda_datahub_query]]
        url = "$DATAHUB_URL"
        port = "$DATAHUB_PORT"
        query_start_time_offset = "0m"
        query_end_time_offset = "6h"
        # If use_query_timestamp is true, agent will use queried timestamp from database as timestamp of the metric.
        # If use_query_timestamp is false, agent will use current timestamp as timestamp of the metric.
        use_query_timestamp = false
        cluster_name = "$CLUSTER_NAME"

        ### Planning ###

        ## Node ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          measurement = "node"
          scope = "planning"
          granularity = "21600"

        ## Namespace ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          measurement = "namespace"
          scope = "planning"
          granularity = "21600"

        ## Controller ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          name = "<general_application_name>"
          namespace = "<general_application_namespace>"
          measurement = "controller"
          scope = "planning"
          granularity = "21600"

      ## This plugin is for future 24 hours planning
      [[inputs.alameda_datahub_query]]
        url = "$DATAHUB_URL"
        port = "$DATAHUB_PORT"
        query_start_time_offset = "0m"
        query_end_time_offset = "24h"
        # If use_query_timestamp is true, agent will use queried timestamp from database as timestamp of the metric.
        # If use_query_timestamp is false, agent will use current timestamp as timestamp of the metric.
        use_query_timestamp = false
        cluster_name = "$CLUSTER_NAME"

        ### Planning ###

        ## Node ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          measurement = "node"
          scope = "planning"
          granularity = "86400"

        ## Namespace ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          measurement = "namespace"
          scope = "planning"
          granularity = "86400"

        ## Controller ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          name = "<general_application_name>"
          namespace = "<general_application_namespace>"
          measurement = "controller"
          scope = "planning"
          granularity = "86400"

      ## All non-recommendation type metric will use past time, we gather all non-recommendation type metric together.
      [[inputs.alameda_datahub_query]]
        url = "$DATAHUB_URL"
        port = "$DATAHUB_PORT"
        query_start_time_offset = "-1m"
        query_end_time_offset = "0m"
        # If use_query_timestamp is true, agent will use queried timestamp from database as timestamp of the metric.
        # If use_query_timestamp is false, agent will use current timestamp as timestamp of the metric.
        use_query_timestamp = true
        cluster_name = "$CLUSTER_NAME"

        ### Prediction ###

        ## Node ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          measurement = "node"
          scope = "prediction"

        ## Namespace ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          measurement = "namespace"
          scope = "prediction"

        ## Controller ##
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          name = "<general_application_name>"
          namespace = "<general_application_namespace>"
          measurement = "controller"
          scope = "prediction"

        ## Application-aware - Kafka ##
        [[inputs.alameda_datahub_query.watched_source]]
          name = "<kafka_consumer_group_name>"
          namespace = "<kafka_consumer_group_namespace>"
          measurement = "kafka_consumer_group_current_offset"
          scope = "prediction"

        [[inputs.alameda_datahub_query.watched_source]]
          name = "<kafka_topic_name>"
          namespace = "<kafka_topic_namespace>"
          measurement = "kafka_topic_partition_current_offset"
          scope = "prediction"

      ## This plugin is for past 1 hour fedemeter metrics
      [[inputs.alameda_datahub_query]]
        url = "$DATAHUB_URL"
        port = "$DATAHUB_PORT"
        query_start_time_offset = "-1h"
        query_end_time_offset = "0m"
        # If use_query_timestamp is true, agent will use queried timestamp from database as timestamp of the metric.
        # If use_query_timestamp is false, agent will use current timestamp as timestamp of the metric.
        use_query_timestamp = true
        cluster_name = "$CLUSTER_NAME"

        ### Fedemeter ###

        ## Cost Analysis - Current Cost
        [[inputs.alameda_datahub_query.watched_source]] # Cost Analysis config
          measurement = "calculation_price_instance"
          scope = "fedemeter"
          granularity = "3600"

        ## Cost Allocation - Namespace Historical Cost
        [[inputs.alameda_datahub_query.watched_source]] # Cost Analysis config
          measurement = "resource_history_cost_namespace"
          scope = "fedemeter"
          granularity = "3600"

      ## All recommendation type metric will use future time, we gather all recommendation type metric together.
      [[inputs.alameda_datahub_query]]
        url = "$DATAHUB_URL"
        port = "$DATAHUB_PORT"
        query_start_time_offset = "0m"
        query_end_time_offset = "3m"
        # If use_query_timestamp is true, agent will use queried timestamp from database as timestamp of the metric.
        # If use_query_timestamp is false, agent will use current timestamp as timestamp of the metric.
        use_query_timestamp = true
        cluster_name = "$CLUSTER_NAME"

        ## Controller
        [[inputs.alameda_datahub_query.watched_source]] #General Application config
          name = "<general_application_name>"
          namespace = "<general_application_namespace>"
          measurement = "controller"
          scope = "recommendation"

        ## Application-aware - Kafka
        [[inputs.alameda_datahub_query.watched_source]]
          name = "<kafka_consumer_group_name>"
          namespace = "<kafka_consumer_group_namespace>"
          measurement = "kafka_consumer_group"
          scope = "recommendation"

      [[outputs.datahub]]
        url = "$DATAHUB_URL"
        port = "$DATAHUB_PORT"

      #[[inputs.prometheus_query]]
      #  url = "$PROMETHEUS_URL"
      #  token_path = "/var/run/secrets/kubernetes.io/serviceaccount/token"
      #  insecure_skip_verify = true
      #  watched_source = [{name="kafka_topic_partition_current_offset",expr="sum(rate(kafka_topic_partition_current_offset[1m]))by(consumergroup,topic,namespace)",tags=["consumergroup","topic","namespace"]},{name="kafka_consumer_group_current_offset",expr="sum(rate(kafka_consumergroup_current_offset[1m]))by(consumergroup,topic,namespace)",tags=["consumergroup","topic","namespace"]},{name="kafka_consumer_group_lag",expr="sum(kafka_consumergroup_lag)by(namespace,consumergroup,topic)",tags=["consumergroup","topic","namespace"]}]

      [[outputs.datadog]]
        api_key = "$DATADOG_API_KEY"
        application_key = "$DATADOG_APPLICATION_KEY"
        User-Agent = "Federator.ai/4.2"
        kafka_dashboards = ["/etc/telegraf/dashboards/datadog/kafka/overview.json"]
        general_dashboards = ["/etc/telegraf/dashboards/datadog/kubernetes/application-overview.json", "/etc/telegraf/dashboards/datadog/kubernetes/cluster-overview.json", "/etc/telegraf/dashboards/datadog/cost/cost-analysis-overview.json"]
        enable_kafka_dashboard = false
        enable_general_dashboard = false

        # This pattern support federatorai.integration.status, federatorai.recommendation and federatorai.prediction.*
        [[outputs.datadog.integration_metrics]]
          name="federatorai.*"
          aggregation_type="raw"

        [[outputs.datadog.integration_metrics]]
          name="kafka_topic_partition_current_offset"
          aggregation_type="diff"

        [[outputs.datadog.integration_metrics]]
          name="kafka_consumer_group_current_offset"
          aggregation_type="diff"

      # anchor
      [[inputs.datadog]]
        urls = ["$DATADOG_QUERY_URL"]
        api_key = "$DATADOG_API_KEY"
        application_key = "$DATADOG_APPLICATION_KEY"
        cluster_name = "$CLUSTER_NAME"
        ## Cloud metric has 5 minutes to 10 minutes delay
        cloud_metric_delay_interval = "30m0s"
        ## Set default cloud information ifneeded
        enable_set_default_cloud_info_if_empty = true
        default_provider = "aws"
        default_region = "us-west-1"
        default_instance_type = "m5.4xlarge"
        default_instance_id = "i-00cd730e045190cad"
        default_zone = "us-west-1a"
        excluded_namespaces = ["kube-public", "kube-service-catalog", "kube-system", "management-infra", "kube-node-lease", "stackpoint-system", "marketplace", "openshift", "openshift-*"]
        # Watched source
        # TOML format reference: https://github.com/influxdata/toml/blob/master/README.md
        [[inputs.datadog.watched_source]]
          namespace = "<monitored_application_namespace>"
          application = "<monitored_application>"
          min_replicas = 0 # monitored_application_min_replicas
          max_replicas = 0 # monitored_application_max_replicas
          [[inputs.datadog.watched_source.watched_metrics]]
            name="kubernetes.cpu.usage.total"
            metric_type="CPU_MILLICORES_USAGE"
          [[inputs.datadog.watched_source.watched_metrics]]
            name="kubernetes.memory.usage"
            metric_type="MEMORY_BYTES_USAGE"

      [[inputs.datadog_application_aware]]
        urls = ["$DATADOG_QUERY_URL"]
        api_key = "$DATADOG_API_KEY"
        application_key = "$DATADOG_APPLICATION_KEY"
        cluster_name = "$CLUSTER_NAME"

        [[inputs.datadog_application_aware.watched_source]]
          namespace = ""
          application = ""
          category="kafka"
          service=""
          min_replicas = 0
          max_replicas = 0
          [[inputs.datadog_application_aware.watched_source.watched_metrics]]
            name="kafka.broker_offset"
            [inputs.datadog_application_aware.watched_source.watched_metrics.scope]
              topic = "<kafka_topic_name>"
          [[inputs.datadog_application_aware.watched_source.watched_metrics]]
            name="kafka.consumer_offset"
            [inputs.datadog_application_aware.watched_source.watched_metrics.scope]
              topic = "<kafka_topic_name>"
              consumer_group = "<kafka_consumer_group_name>"
          [[inputs.datadog_application_aware.watched_source.watched_metrics]]
            name="kafka.consumer_lag"
            [inputs.datadog_application_aware.watched_source.watched_metrics.scope]
              topic = "<kafka_topic_name>"
              consumer_group = "<kafka_consumer_group_name>"
