apiVersion: v1
kind: ConfigMap
metadata:
  name: federatorai-data-adapter-config
  namespace: {{.NameSpace}}
data:
    telegraf.conf: |+
      [global_tags]

      [agent]
        interval = "1m"
        round_interval = false
        metric_batch_size = 1000
        metric_buffer_limit = 10000
        collection_jitter = "0s"
        flush_interval = "30s"
        flush_jitter = "0s"
        precision = "1us"
        debug = true
        logfile = "/var/log/telegraf.log"
        logfile_rotation_interval = "1d"
        logfile_rotation_max_archives = 7
        logfile_rotation_max_size = "100MB"
        quiet = false
        hostname = ""
        omit_hostname = false

      [[aggregators.basicstats]]
        period = "1m"
        granularity = "1m"
        drop_original = true

      [[outputs.datahub]]
        url = "$DATAHUB_URL"
        port = "$DATAHUB_PORT"

      #[[inputs.datadog]]
      #  urls = ["$DATADOG_QUERY_URL"]
      #  api_key = "$DATADOG_API_KEY"
      #  application_key = "$DATADOG_APPLICATION_KEY"
      #  # If we keep CLUSTER_NAME value empty, the agent will get k8s cluster name automatically.
      #  cluster_name = "$CLUSTER_NAME"
      #  # Watched source
      #  # TOML format reference: https://github.com/influxdata/toml/blob/master/README.md
      #  [[inputs.datadog.watched_source]]
      #    namespace = "<monitored_application_namespace>"
      #    application = "<monitored_application>"
      #    [[inputs.datadog.watched_source.watched_metrics]]
      #      name="kubernetes.cpu.usage.total"
      #      metric_type="CPU_USAGE_SECONDS_PERCENTAGE"
      #    [[inputs.datadog.watched_source.watched_metrics]]
      #      name="kubernetes.memory.usage"
      #      metric_type="MEMORY_USAGE_BYTES"

      #  [[inputs.datadog.watched_source]]
      #    namespace = "<monitored_application_namespace>"
      #    application = "<monitored_application>"
      #    [[inputs.datadog.watched_source.watched_metrics]]
      #      name="kubernetes.cpu.usage.total"
      #      metric_type="CPU_USAGE_SECONDS_PERCENTAGE"
      #    [[inputs.datadog.watched_source.watched_metrics]]
      #      name="kubernetes.memory.usage"
      #      metric_type="MEMORY_USAGE_BYTES"

      [[inputs.datadog_application_aware]]
        urls = ["$DATADOG_QUERY_URL"]
        api_key = "$DATADOG_API_KEY"
        application_key = "$DATADOG_APPLICATION_KEY"
        # If we keep CLUSTER_NAME value empty, the agent will get k8s cluster name automatically.
        cluster_name = "$CLUSTER_NAME"

        [inputs.datadog_application_aware.watched_kafka_consumer]
          application = ""
          namespace = ""
          min_replicas = 0
          max_replicas = 0

      #[[inputs.prometheus_query]]
      #  url = "$PROMETHEUS_URL"
      #  token_path = "/var/run/secrets/kubernetes.io/serviceaccount/token"
      #  insecure_skip_verify = true
      #  watched_source = [{name="kafka_topic_partition_current_offset",expr="sum(rate(kafka_topic_partition_current_offset[1m]))by(consumergroup,topic,namespace)",tags=["consumergroup","topic","namespace"]},{name="kafka_consumer_group_current_offset",expr="sum(rate(kafka_consumergroup_current_offset[1m]))by(consumergroup,topic,namespace)",tags=["consumergroup","topic","namespace"]},{name="kafka_consumer_group_lag",expr="sum(kafka_consumergroup_lag)by(namespace,consumergroup,topic)",tags=["consumergroup","topic","namespace"]}]

      [[inputs.alameda_datahub_query]]
        url = "$DATAHUB_URL"
        port = "$DATAHUB_PORT"
        ##The recommendation query range, unit: minutes
        recommendation_interval = 5
        # If we keep CLUSTER_NAME value empty, the agent will get k8s cluster name automatically.
        cluster_name = "$CLUSTER_NAME"

        [[inputs.alameda_datahub_query.watched_source]]
          name = "<kafka_consumer_group_name>"
          namespace = "<kafka_consumer_group_namespace>"
          measurement = "kafka_consumer_group"
          scope = "recommendation"

        [[inputs.alameda_datahub_query.watched_source]]
          name = "<kafka_consumer_group_name>"
          namespace = "<kafka_consumer_grou_namespace>"
          measurement = "kafka_consumer_group_current_offset"
          scope = "prediction"

        [[inputs.alameda_datahub_query.watched_source]]
          name = "<kafka_topic_name>"
          namespace = "<kafka_topic_namespace>"
          measurement = "kafka_topic_partition_current_offset"
          scope = "prediction"

      [[outputs.datadog]]
        api_key = "$DATADOG_API_KEY"
        application_key = "$DATADOG_APPLICATION_KEY"
        User-Agent = "Federator.ai/4.2"
        integration_metrics = ["federatorai.recommendation","federatorai.prediction"]
        dashboard_dir = "/etc/telegraf/dashboards/datadog"
        enable_kafka_dashboard = true
